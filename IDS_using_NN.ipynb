{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Mahim05078/CSE6813--FedLearning-MLP-IDS-Systems/blob/master/IDS_using_NN.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LG3itamFLNj_",
        "outputId": "b0471297-a01d-4b6e-ba7c-97572f0e568f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'NSL-KDD-Dataset'...\n",
            "remote: Enumerating objects: 15, done.\u001b[K\n",
            "remote: Counting objects: 100% (15/15), done.\u001b[K\n",
            "remote: Compressing objects: 100% (7/7), done.\u001b[K\n",
            "remote: Total 15 (delta 6), reused 15 (delta 6), pack-reused 0\u001b[K\n",
            "Unpacking objects: 100% (15/15), 5.13 MiB | 2.66 MiB/s, done.\n"
          ]
        }
      ],
      "source": [
        "# So first we need to download our dataset...\n",
        "# It can be found in from this url..\n",
        "!git clone 'https://github.com/Mahim05078/NSL-KDD-Dataset.git'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Gbt0RFNFHGIO"
      },
      "outputs": [],
      "source": [
        "#import basic libraries\n",
        "import os\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.svm import OneClassSVM\n",
        "from sklearn import decomposition, preprocessing, svm"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BCCkhwU1NB4d",
        "outputId": "d15418d4-32d0-4af7-f760-4f33fab55f07"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "/content\n"
          ]
        }
      ],
      "source": [
        "print(os.getcwd())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-8W5ZEcyL9P1"
      },
      "outputs": [],
      "source": [
        "#load the necessary features from training testing and validation data\n",
        "data = pd.read_csv('NSL-KDD-Dataset/input/nslkdd/KDDTrain+.txt',header = None, names=['duration','protocol_type','service','flag','src_bytes','dst_bytes','land','wrong_fragment','urgent'\n",
        "            ,'hot','num_failed_logins','logged_in','num_compromised','root_shell','su_attempted','num_root'\n",
        "            ,'num_file_creations','num_shells','num_access_files','num_outbound_cmds','is_host_login'\n",
        "            ,'is_guest_login','count','srv_count','serror_rate','srv_serror_rate','rerror_rate','srv_rerror_rate'\n",
        "            ,'same_srv_rate','diff_srv_rate','srv_diff_host_rate','dst_host_count','dst_host_srv_count'\n",
        "            ,'dst_host_same_srv_rate','dst_host_diff_srv_rate','dst_host_same_src_port_rate'\n",
        "            ,'dst_host_srv_diff_host_rate','dst_host_serror_rate','dst_host_srv_serror_rate','dst_host_rerror_rate'\n",
        "            ,'dst_host_srv_rerror_rate','attack','outcome'])\n",
        "\n",
        "testpl = pd.read_csv('NSL-KDD-Dataset/input/nslkdd/KDDTest+.txt',header = None,names=['duration','protocol_type','service','flag','src_bytes','dst_bytes','land','wrong_fragment','urgent'\n",
        "            ,'hot','num_failed_logins','logged_in','num_compromised','root_shell','su_attempted','num_root'\n",
        "            ,'num_file_creations','num_shells','num_access_files','num_outbound_cmds','is_host_login'\n",
        "            ,'is_guest_login','count','srv_count','serror_rate','srv_serror_rate','rerror_rate','srv_rerror_rate'\n",
        "            ,'same_srv_rate','diff_srv_rate','srv_diff_host_rate','dst_host_count','dst_host_srv_count'\n",
        "            ,'dst_host_same_srv_rate','dst_host_diff_srv_rate','dst_host_same_src_port_rate'\n",
        "            ,'dst_host_srv_diff_host_rate','dst_host_serror_rate','dst_host_srv_serror_rate','dst_host_rerror_rate'\n",
        "            ,'dst_host_srv_rerror_rate','attack','outcome'])\n",
        "\n",
        "valid = pd.read_csv('NSL-KDD-Dataset/input/nslkdd/KDDTest-21.txt',header = None,names=['duration','protocol_type','service','flag','src_bytes','dst_bytes','land','wrong_fragment','urgent'\n",
        "            ,'hot','num_failed_logins','logged_in','num_compromised','root_shell','su_attempted','num_root'\n",
        "            ,'num_file_creations','num_shells','num_access_files','num_outbound_cmds','is_host_login'\n",
        "            ,'is_guest_login','count','srv_count','serror_rate','srv_serror_rate','rerror_rate','srv_rerror_rate'\n",
        "            ,'same_srv_rate','diff_srv_rate','srv_diff_host_rate','dst_host_count','dst_host_srv_count'\n",
        "            ,'dst_host_same_srv_rate','dst_host_diff_srv_rate','dst_host_same_src_port_rate'\n",
        "            ,'dst_host_srv_diff_host_rate','dst_host_serror_rate','dst_host_srv_serror_rate','dst_host_rerror_rate'\n",
        "            ,'dst_host_srv_rerror_rate','attack','outcome'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GjKTG04gNkix"
      },
      "outputs": [],
      "source": [
        "#Preprocess to encode non numeric data\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "\n",
        "for i in ['protocol_type',\"service\",\"flag\"]:\n",
        "    encoder = LabelEncoder()\n",
        "    fi = pd.concat([data[i],testpl[i]]).values\n",
        "    encoder.fit(fi)\n",
        "    data[i] = encoder.transform(data[i])\n",
        "    testpl[i] = encoder.transform(testpl[i])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dEc_sM8nNsEB"
      },
      "outputs": [],
      "source": [
        "#Relable the loaded data into 5 major classes\n",
        "def lab(data):\n",
        "\n",
        "    classlist = []\n",
        "\n",
        "    check1 = (\"apache2\",\"back\",\"land\",\"neptune\",\"mailbomb\",\"pod\",\"processtable\",\"smurf\",\"teardrop\",\"udpstorm\",\"worm\")\n",
        "    check2 = (\"ipsweep\",\"mscan\",\"nmap\",\"portsweep\",\"saint\",\"satan\")\n",
        "    check3 = (\"buffer_overflow\",\"loadmodule\",\"perl\",\"ps\",\"rootkit\",\"sqlattack\",\"xterm\")\n",
        "    check4 = (\"ftp_write\",\"guess_passwd\",\"httptunnel\",\"imap\",\"multihop\",\"named\",\"phf\",\"sendmail\",\"Snmpgetattack\",\"spy\",\"snmpguess\",\"warezclient\",\"warezmaster\",\"xlock\",\"xsnoop\")\n",
        "\n",
        "\n",
        "    for item in data.pop('attack'):\n",
        "        if item in check1:\n",
        "            classlist.append(\"DoS\")\n",
        "        elif item in check2:\n",
        "            classlist.append(\"Probe\")\n",
        "        elif item in check3:\n",
        "            classlist.append(\"U2R\")\n",
        "        elif item in check4:\n",
        "            classlist.append(\"R2L\")\n",
        "        else:\n",
        "            classlist.append(\"Normal\")\n",
        "\n",
        "    return classlist"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AM1KUErKNu-I"
      },
      "outputs": [],
      "source": [
        "#seperating output vectors\n",
        "y_train = np.array(lab(data))\n",
        "y_test = np.array(lab(testpl))\n",
        "y_valid = np.array(lab(valid))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6JXROMIJNyVk",
        "outputId": "d3f3df81-9629-46f6-8717-df0522bc9b8e"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "duration                         int64\n",
              "protocol_type                    int64\n",
              "service                          int64\n",
              "flag                             int64\n",
              "src_bytes                        int64\n",
              "dst_bytes                        int64\n",
              "land                             int64\n",
              "wrong_fragment                   int64\n",
              "urgent                           int64\n",
              "hot                              int64\n",
              "num_failed_logins                int64\n",
              "logged_in                        int64\n",
              "num_compromised                  int64\n",
              "root_shell                       int64\n",
              "su_attempted                     int64\n",
              "num_root                         int64\n",
              "num_file_creations               int64\n",
              "num_shells                       int64\n",
              "num_access_files                 int64\n",
              "num_outbound_cmds                int64\n",
              "is_host_login                    int64\n",
              "is_guest_login                   int64\n",
              "count                            int64\n",
              "srv_count                        int64\n",
              "serror_rate                    float64\n",
              "srv_serror_rate                float64\n",
              "rerror_rate                    float64\n",
              "srv_rerror_rate                float64\n",
              "same_srv_rate                  float64\n",
              "diff_srv_rate                  float64\n",
              "srv_diff_host_rate             float64\n",
              "dst_host_count                   int64\n",
              "dst_host_srv_count               int64\n",
              "dst_host_same_srv_rate         float64\n",
              "dst_host_diff_srv_rate         float64\n",
              "dst_host_same_src_port_rate    float64\n",
              "dst_host_srv_diff_host_rate    float64\n",
              "dst_host_serror_rate           float64\n",
              "dst_host_srv_serror_rate       float64\n",
              "dst_host_rerror_rate           float64\n",
              "dst_host_srv_rerror_rate       float64\n",
              "outcome                          int64\n",
              "dtype: object"
            ]
          },
          "execution_count": 7,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "data.dtypes"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 403
        },
        "id": "L8aWT7_AN0tn",
        "outputId": "3be5a0e0-cc8f-4ea6-ddd0-24b1fc8a5394"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-7-fe0b009bacc3>:11: FutureWarning: In a future version of pandas all arguments of DataFrame.drop except for the argument 'labels' will be keyword-only.\n",
            "  df = df.drop(each, 1)\n",
            "<ipython-input-7-fe0b009bacc3>:11: FutureWarning: In a future version of pandas all arguments of DataFrame.drop except for the argument 'labels' will be keyword-only.\n",
            "  df = df.drop(each, 1)\n",
            "<ipython-input-7-fe0b009bacc3>:11: FutureWarning: In a future version of pandas all arguments of DataFrame.drop except for the argument 'labels' will be keyword-only.\n",
            "  df = df.drop(each, 1)\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "   duration     src_bytes     dst_bytes  land  wrong_fragment  urgent  hot  \\\n",
              "0       0.0  3.558064e-07  0.000000e+00   0.0             0.0     0.0  0.0   \n",
              "1       0.0  1.057999e-07  0.000000e+00   0.0             0.0     0.0  0.0   \n",
              "2       0.0  0.000000e+00  0.000000e+00   0.0             0.0     0.0  0.0   \n",
              "3       0.0  1.681203e-07  6.223962e-06   0.0             0.0     0.0  0.0   \n",
              "4       0.0  1.442067e-07  3.206260e-07   0.0             0.0     0.0  0.0   \n",
              "\n",
              "   num_failed_logins  logged_in  num_compromised  ...  flag_1  flag_2  flag_3  \\\n",
              "0                0.0        0.0              0.0  ...     0.0     0.0     0.0   \n",
              "1                0.0        0.0              0.0  ...     0.0     0.0     0.0   \n",
              "2                0.0        0.0              0.0  ...     0.0     0.0     0.0   \n",
              "3                0.0        1.0              0.0  ...     0.0     0.0     0.0   \n",
              "4                0.0        1.0              0.0  ...     0.0     0.0     0.0   \n",
              "\n",
              "   flag_4  flag_5  flag_6  flag_7  flag_8  flag_9  flag_10  \n",
              "0     0.0     0.0     0.0     0.0     0.0     1.0        0  \n",
              "1     0.0     0.0     0.0     0.0     0.0     1.0        0  \n",
              "2     0.0     1.0     0.0     0.0     0.0     0.0        0  \n",
              "3     0.0     0.0     0.0     0.0     0.0     1.0        0  \n",
              "4     0.0     0.0     0.0     0.0     0.0     1.0        0  \n",
              "\n",
              "[5 rows x 123 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-a1d99071-c678-4447-a747-0aa931afd05d\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>duration</th>\n",
              "      <th>src_bytes</th>\n",
              "      <th>dst_bytes</th>\n",
              "      <th>land</th>\n",
              "      <th>wrong_fragment</th>\n",
              "      <th>urgent</th>\n",
              "      <th>hot</th>\n",
              "      <th>num_failed_logins</th>\n",
              "      <th>logged_in</th>\n",
              "      <th>num_compromised</th>\n",
              "      <th>...</th>\n",
              "      <th>flag_1</th>\n",
              "      <th>flag_2</th>\n",
              "      <th>flag_3</th>\n",
              "      <th>flag_4</th>\n",
              "      <th>flag_5</th>\n",
              "      <th>flag_6</th>\n",
              "      <th>flag_7</th>\n",
              "      <th>flag_8</th>\n",
              "      <th>flag_9</th>\n",
              "      <th>flag_10</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0.0</td>\n",
              "      <td>3.558064e-07</td>\n",
              "      <td>0.000000e+00</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0.0</td>\n",
              "      <td>1.057999e-07</td>\n",
              "      <td>0.000000e+00</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000e+00</td>\n",
              "      <td>0.000000e+00</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0.0</td>\n",
              "      <td>1.681203e-07</td>\n",
              "      <td>6.223962e-06</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0.0</td>\n",
              "      <td>1.442067e-07</td>\n",
              "      <td>3.206260e-07</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>5 rows × 123 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-a1d99071-c678-4447-a747-0aa931afd05d')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-a1d99071-c678-4447-a747-0aa931afd05d button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-a1d99071-c678-4447-a747-0aa931afd05d');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ],
      "source": [
        "#One-hot encoding\n",
        "def one_hot(df, cols):\n",
        "    \"\"\"\n",
        "    @param df pandas DataFrame\n",
        "    @param cols a list of columns to encode\n",
        "    @return a DataFrame with one-hot encoding\n",
        "    \"\"\"\n",
        "    for each in cols:\n",
        "        dummies = pd.get_dummies(df[each], prefix=each, drop_first=False)\n",
        "        df = pd.concat([df, dummies], axis=1)\n",
        "        df = df.drop(each, 1)\n",
        "    return df\n",
        "#Merging train and test data\n",
        "combined_data = pd.concat([data,testpl])\n",
        "#Applying one hot encoding to combined data\n",
        "combined_data = one_hot(combined_data,['protocol_type',\"service\",'flag'])\n",
        "#Function to min-max normalize\n",
        "def normalize(df, cols):\n",
        "    \"\"\"\n",
        "    @param df pandas DataFrame\n",
        "    @param cols a list of columns to encode\n",
        "    @return a DataFrame with normalized specified features\n",
        "    \"\"\"\n",
        "    result = df.copy() # do not touch the original df\n",
        "    for feature_name in cols:\n",
        "        max_value = df[feature_name].max()\n",
        "        min_value = df[feature_name].min()\n",
        "        if max_value > min_value:\n",
        "            result[feature_name] = (df[feature_name] - min_value) / (max_value - min_value)\n",
        "    return result\n",
        "\n",
        "#Normalizing training set\n",
        "combined_data = normalize(combined_data,combined_data.columns[:-1])\n",
        "combined_data.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fiaSgqUwN43G",
        "outputId": "7c5697dd-4da7-4101-a594-89fe7fde9bad"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-8-f222414c2405>:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  data['attack'] = y_train\n",
            "<ipython-input-8-f222414c2405>:3: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  data['attack'] = y_train\n"
          ]
        }
      ],
      "source": [
        "data = combined_data[:len(data)]\n",
        "# data = combined_data.concat(axis=1).copy()\n",
        "data['attack'] = y_train\n",
        "testpl = combined_data[len(data):]\n",
        "# testpl =  combined_data.concat(axis=1).copy()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IQFH6RqcN-QK"
      },
      "outputs": [],
      "source": [
        "# maj_3 = data.loc[(data['attack']!='U2R') & (data['attack']!='R2L')]\n",
        "maj_3 = data.loc[(data['attack']!= 'None')]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8XvYp34wOYMm",
        "outputId": "a958e5a7-857e-412c-bb50-adc14762a118"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting tensorflow_addons\n",
            "  Downloading tensorflow_addons-0.20.0-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (591 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m591.0/591.0 kB\u001b[0m \u001b[31m11.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting typeguard<3.0.0,>=2.7\n",
            "  Downloading typeguard-2.13.3-py3-none-any.whl (17 kB)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.9/dist-packages (from tensorflow_addons) (23.0)\n",
            "Installing collected packages: typeguard, tensorflow_addons\n",
            "Successfully installed tensorflow_addons-0.20.0 typeguard-2.13.3\n"
          ]
        }
      ],
      "source": [
        "!pip install tensorflow_addons"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FmsrfI8vOEAp",
        "outputId": "f0c50c23-043e-43c0-84a7-4ac4eff35954"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.9/dist-packages/sklearn/preprocessing/_encoders.py:868: FutureWarning: `sparse` was renamed to `sparse_output` in version 1.2 and will be removed in 1.4. `sparse_output` is ignored unless you leave `sparse` to its default value.\n",
            "  warnings.warn(\n"
          ]
        }
      ],
      "source": [
        "from sklearn.preprocessing import OneHotEncoder\n",
        "encoder = OneHotEncoder(sparse=False)\n",
        "# apply on df\n",
        "encoder.fit(data['attack'].values.reshape(-1,1))\n",
        "color_1hot = encoder.transform(maj_3['attack'].values.reshape(-1,1))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tneujP3hOBvK",
        "outputId": "0997312a-84a7-4640-dadf-a7b919e4f5c2"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.9/dist-packages/tensorflow_addons/utils/tfa_eol_msg.py:23: UserWarning: \n",
            "\n",
            "TensorFlow Addons (TFA) has ended development and introduction of new features.\n",
            "TFA has entered a minimal maintenance and release mode until a planned end of life in May 2024.\n",
            "Please modify downstream libraries to take dependencies from other repositories in our TensorFlow community (e.g. Keras, Keras-CV, and Keras-NLP). \n",
            "\n",
            "For more information see: https://github.com/tensorflow/addons/issues/2807 \n",
            "\n",
            "  warnings.warn(\n"
          ]
        }
      ],
      "source": [
        "#Customizing the MLP model\n",
        "import tensorflow as tf\n",
        "import tensorflow_addons as tfa\n",
        "\n",
        "model = tf.keras.models.Sequential()\n",
        "model.add(tf.keras.layers.Dense(units = 64, activation = 'relu', input_shape = (maj_3.shape[1]-1,)))\n",
        "model.add(tf.keras.layers.Dense(units = 128, activation = 'relu'))\n",
        "model.add(tf.keras.layers.Dense(units = 5, activation = 'softmax'))\n",
        "model.compile(optimizer = 'adam', loss = 'categorical_crossentropy', metrics = [tf.keras.metrics.CategoricalAccuracy(),\n",
        "                           tfa.metrics.F1Score(num_classes=5, average='macro'),\n",
        "                           tfa.metrics.FBetaScore(beta=2.0, num_classes=5, average='macro')])\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9WLUCboMPVuA",
        "outputId": "3e4f4c17-05da-47f9-fe56-ce198d3f573c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/10\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.9/dist-packages/tensorflow/python/data/ops/structured_function.py:254: UserWarning: Even though the `tf.config.experimental_run_functions_eagerly` option is set, this option does not apply to tf.data functions. To force eager execution of tf.data functions, please use `tf.data.experimental.enable_debug_mode()`.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "3150/3150 [==============================] - 158s 49ms/step - loss: 0.0441 - categorical_accuracy: 0.9874 - f1_score: 0.7676 - fbeta_score: 0.7612 - val_loss: 0.0148 - val_categorical_accuracy: 0.9954 - val_f1_score: 0.8533 - val_fbeta_score: 0.8358\n",
            "Epoch 2/10\n",
            "3150/3150 [==============================] - 153s 49ms/step - loss: 0.0131 - categorical_accuracy: 0.9955 - f1_score: 0.9171 - fbeta_score: 0.9023 - val_loss: 0.0111 - val_categorical_accuracy: 0.9967 - val_f1_score: 0.8207 - val_fbeta_score: 0.8135\n",
            "Epoch 3/10\n",
            "3150/3150 [==============================] - 152s 48ms/step - loss: 0.0101 - categorical_accuracy: 0.9964 - f1_score: 0.9357 - fbeta_score: 0.9257 - val_loss: 0.0108 - val_categorical_accuracy: 0.9967 - val_f1_score: 0.8780 - val_fbeta_score: 0.8600\n",
            "Epoch 4/10\n",
            "3064/3150 [============================>.] - ETA: 3s - loss: 0.0085 - categorical_accuracy: 0.9967 - f1_score: 0.9429 - fbeta_score: 0.9320"
          ]
        }
      ],
      "source": [
        "#Training the model on training data for 20 epochs with 80/20 training/validation split\n",
        "tf.config.run_functions_eagerly(True)\n",
        "\n",
        "model.fit(maj_3.drop(columns=['attack']).values, color_1hot, epochs = 20 ,validation_split=0.2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Om_WYuOegLAU",
        "outputId": "95dd6894-43fa-453d-f2d3-c96eb5342272"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            " 10/705 [..............................] - ETA: 4s "
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/tensorflow/python/data/ops/structured_function.py:256: UserWarning: Even though the `tf.config.experimental_run_functions_eagerly` option is set, this option does not apply to tf.data functions. To force eager execution of tf.data functions, please use `tf.data.experimental.enable_debug_mode()`.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "705/705 [==============================] - 8s 11ms/step\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.95      0.85      0.90      7460\n",
            "           1       0.71      0.96      0.81      9889\n",
            "           2       0.80      0.63      0.70      2421\n",
            "           3       0.70      0.09      0.16      2707\n",
            "           4       0.26      0.67      0.37        67\n",
            "\n",
            "    accuracy                           0.78     22544\n",
            "   macro avg       0.68      0.64      0.59     22544\n",
            "weighted avg       0.79      0.78      0.75     22544\n",
            "\n"
          ]
        }
      ],
      "source": [
        "#Summarize precision, recall and F1 score for each classes\n",
        "from sklearn.metrics import classification_report\n",
        "\n",
        "print(classification_report(np.argmax(encoder.transform(y_test.reshape(-1,1)),axis=1),np.argmax(model.predict(testpl.values),axis=1)))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Jn2LykWEgL_L"
      },
      "outputs": [],
      "source": [
        "\n",
        "from imblearn.over_sampling import SMOTE, ADASYN\n",
        "X_resampled, y_resampled = ADASYN(sampling_strategy = 'minority').fit_resample(data.drop(columns=['attack']).values,data['attack'].values)\n",
        "X_resampled, y_resampled = ADASYN(sampling_strategy = 'minority').fit_resample(X_resampled, y_resampled)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Jososm7AgcHF"
      },
      "outputs": [],
      "source": [
        "from imblearn.under_sampling import RandomUnderSampler\n",
        "rus = RandomUnderSampler(random_state=0)\n",
        "X_resampled, y_resampled = rus.fit_resample(data.drop(columns=['attack']).values,data['attack'].values)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LKaE5KowgQQY"
      },
      "outputs": [],
      "source": [
        "y_resampled = encoder.transform(y_resampled.reshape(-1,1))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MEkr80IugS5T"
      },
      "outputs": [],
      "source": [
        "import sklearn\n",
        "weights=sklearn.utils.class_weight.compute_class_weight(class_weight='balanced', classes=data['attack'].unique().tolist(), y=data['attack']).tolist()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aNisVeUj3q_p",
        "outputId": "3cdc6851-f851-4d27-8807-3f88191a763c"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(260, 5)"
            ]
          },
          "execution_count": 26,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "y_resampled.shape\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "buTEwevxghHl",
        "outputId": "462ce375-529f-4fe8-a840-90a34a6d849a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/5\n",
            "9/9 [==============================] - 1s 112ms/step - loss: 0.1515 - categorical_accuracy: 0.9846 - f1_score: 0.9846 - fbeta_score: 0.9845\n",
            "Epoch 2/5\n",
            "9/9 [==============================] - 1s 104ms/step - loss: 0.1640 - categorical_accuracy: 0.9808 - f1_score: 0.9807 - fbeta_score: 0.9805\n",
            "Epoch 3/5\n",
            "9/9 [==============================] - 0s 46ms/step - loss: 0.1474 - categorical_accuracy: 0.9808 - f1_score: 0.9807 - fbeta_score: 0.9805\n",
            "Epoch 4/5\n",
            "9/9 [==============================] - 0s 42ms/step - loss: 0.1454 - categorical_accuracy: 0.9846 - f1_score: 0.9846 - fbeta_score: 0.9845\n",
            "Epoch 5/5\n",
            "9/9 [==============================] - 0s 44ms/step - loss: 0.1548 - categorical_accuracy: 0.9885 - f1_score: 0.9885 - fbeta_score: 0.9884\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7fdc4814c850>"
            ]
          },
          "execution_count": 40,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "model.fit(X_resampled, y_resampled,epochs=5,class_weight=dict(enumerate(weights)))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-suLZVgVgo-1",
        "outputId": "8658a8cb-bf95-468f-d633-e7b419ef3aaa"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            " 31/705 [>.............................] - ETA: 2s"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/tensorflow/python/data/ops/structured_function.py:256: UserWarning: Even though the `tf.config.experimental_run_functions_eagerly` option is set, this option does not apply to tf.data functions. To force eager execution of tf.data functions, please use `tf.data.experimental.enable_debug_mode()`.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "705/705 [==============================] - 3s 4ms/step\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.93      0.86      0.90      7460\n",
            "           1       0.81      0.92      0.86      9889\n",
            "           2       0.78      0.73      0.76      2421\n",
            "           3       0.67      0.41      0.51      2707\n",
            "           4       0.10      0.69      0.17        67\n",
            "\n",
            "    accuracy                           0.82     22544\n",
            "   macro avg       0.66      0.72      0.64     22544\n",
            "weighted avg       0.83      0.82      0.82     22544\n",
            "\n"
          ]
        }
      ],
      "source": [
        "print(classification_report(np.argmax(encoder.transform(y_test.reshape(-1,1)),axis=1),np.argmax(model.predict(testpl.values),axis=1)))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0qtsmaGhsQq_",
        "outputId": "f7935bac-52bd-43b0-b13c-9fc0b5155ae6"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "[0.3741235169208381,\n",
              " 0.5485792670977856,\n",
              " 25.321206030150755,\n",
              " 2.1615133836650653,\n",
              " 484.51153846153846]"
            ]
          },
          "execution_count": 18,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "weights"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jFxi5jFtgrny"
      },
      "source": [
        "# Federated Optimization"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9EL31AIqKtiZ"
      },
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UFu6feGVegcE"
      },
      "source": [
        "# Utils"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "775YT8vDo1N_",
        "outputId": "060144f1-6703-4c6d-dc61-28cdfabf9251"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "\u001b[31mERROR: Could not find a version that satisfies the requirement fl_implementation_utils (from versions: none)\u001b[0m\u001b[31m\n",
            "\u001b[0m\u001b[31mERROR: No matching distribution found for fl_implementation_utils\u001b[0m\u001b[31m\n",
            "\u001b[0m"
          ]
        }
      ],
      "source": [
        "# !pip install tensorflow_addons\n",
        "# !pip install fl_implementation_utils"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JVahNHvhejKI",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5b31f095-4f11-4e7d-d0ae-f6adbd1fb76c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.9/dist-packages/tensorflow_addons/utils/tfa_eol_msg.py:23: UserWarning: \n",
            "\n",
            "TensorFlow Addons (TFA) has ended development and introduction of new features.\n",
            "TFA has entered a minimal maintenance and release mode until a planned end of life in May 2024.\n",
            "Please modify downstream libraries to take dependencies from other repositories in our TensorFlow community (e.g. Keras, Keras-CV, and Keras-NLP). \n",
            "\n",
            "For more information see: https://github.com/tensorflow/addons/issues/2807 \n",
            "\n",
            "  warnings.warn(\n"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "import random\n",
        "import os\n",
        "import pickle\n",
        "import pandas as pd\n",
        "\n",
        "#from imutils import paths\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import LabelBinarizer\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.utils import shuffle\n",
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.metrics import classification_report\n",
        "\n",
        "import tensorflow as tf\n",
        "import tensorflow_addons as tfa\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Conv2D\n",
        "from tensorflow.keras.layers import MaxPooling2D\n",
        "from tensorflow.keras.layers import Activation\n",
        "from tensorflow.keras.layers import Flatten\n",
        "from tensorflow.keras.layers import Dense\n",
        "from tensorflow.keras.optimizers import SGD\n",
        "from tensorflow.keras import backend as K\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QmWNMb6mpbuI"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import random\n",
        "import os\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import LabelBinarizer\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.utils import shuffle\n",
        "from sklearn.metrics import accuracy_score\n",
        "from tqdm import tqdm\n",
        "import time"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NloPo49QeolR"
      },
      "outputs": [],
      "source": [
        "def create_clients(data_list, label_list, num_clients=5, initial='clients'):\n",
        "    ''' return: a dictionary with keys clients' names and value as\n",
        "                data shards - tuple of datas and label lists.\n",
        "        args:\n",
        "            data_list: a list of numpy arrays of training data\n",
        "            label_list:a list of binarized labels for each data\n",
        "            num_client: number of fedrated members (clients)\n",
        "            initials: the clients'name prefix, e.g, clients_1\n",
        "\n",
        "    '''\n",
        "\n",
        "    #create a list of client names\n",
        "    client_names = ['{}_{}'.format(initial, i+1) for i in range(num_clients)]\n",
        "\n",
        "    #randomize the data\n",
        "    data = list(zip(data_list, label_list))\n",
        "    random.shuffle(data)\n",
        "\n",
        "    #shard data and place at each client\n",
        "    size = len(data)//num_clients\n",
        "    shards = [data[i:i + size] for i in range(0, size*num_clients, size)]\n",
        "\n",
        "    #number of clients must equal number of shards\n",
        "    assert(len(shards) == len(client_names))\n",
        "\n",
        "    return {client_names[i] : shards[i] for i in range(len(client_names))}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GZOuIFBkfQ5E"
      },
      "outputs": [],
      "source": [
        "def batch_data(data_shard, bs=64):\n",
        "    '''Takes in a clients data shard and create a tfds object off it\n",
        "    args:\n",
        "        shard: a data, label constituting a client's data shard\n",
        "        bs:batch size\n",
        "    return:\n",
        "        tfds object'''\n",
        "    #seperate shard into data and labels lists\n",
        "    data, label = zip(*data_shard)\n",
        "    dataset = tf.data.Dataset.from_tensor_slices((list(data), list(label)))\n",
        "    return dataset.shuffle(len(label)).batch(bs)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TSTw1MPXfY_S"
      },
      "source": [
        "### Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DoMRaaq1fdGn"
      },
      "outputs": [],
      "source": [
        "class LocalModel:\n",
        "    @staticmethod\n",
        "    def build(shape, classes):\n",
        "        model = Sequential()\n",
        "        # model.add(Dense(500,input_shape=(shape,)))\n",
        "        # model.add(Activation(\"relu\"))\n",
        "        # model.add(Dense(300))\n",
        "        # model.add(Activation(\"relu\"))\n",
        "        # model.add(Dense(200))\n",
        "        # model.add(Activation(\"relu\"))\n",
        "        # model.add(Dense(classes))\n",
        "        # model.add(Activation(\"sigmoid\"))\n",
        "        model.add(tf.keras.layers.Dense(units = 64, activation = 'relu', input_shape = (maj_3.shape[1]-1,)))\n",
        "        model.add(tf.keras.layers.Dense(units = 64, activation = 'relu', input_shape = (maj_3.shape[1]-1,)))\n",
        "        model.add(tf.keras.layers.Dense(units = 128, activation = 'relu'))\n",
        "        model.add(tf.keras.layers.Dense(units = classes, activation = 'softmax'))\n",
        "        model.compile(optimizer = 'adam', loss = 'categorical_crossentropy', metrics = [tf.keras.metrics.CategoricalAccuracy(),\n",
        "                           tfa.metrics.F1Score(num_classes=classes, average='macro'),\n",
        "                           tfa.metrics.FBetaScore(beta=2.0, num_classes=classes, average='macro')])\n",
        "        return model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KUaz5a4agP8m"
      },
      "source": [
        "### Weight calculation util"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oslNQaukgYHD"
      },
      "outputs": [],
      "source": [
        "def weight_scalling_factor(clients_trn_data, client_name):\n",
        "    client_names = list(clients_trn_data.keys())\n",
        "    #get the bs\n",
        "    bs = list(clients_trn_data[client_name])[0][0].shape[0]\n",
        "    #first calculate the total training data points across clinets\n",
        "    global_count = sum([tf.data.experimental.cardinality(clients_trn_data[client_name]).numpy() for client_name in client_names])*bs\n",
        "    # get the total number of data points held by a client\n",
        "    local_count = tf.data.experimental.cardinality(clients_trn_data[client_name]).numpy()*bs\n",
        "    return local_count/global_count"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KBRL5WwMghx9"
      },
      "outputs": [],
      "source": [
        "def scale_model_weights(weight, scalar):\n",
        "    '''function for scaling a models weights'''\n",
        "    weight_final = []\n",
        "    steps = len(weight)\n",
        "    for i in range(steps):\n",
        "        weight_final.append(scalar * weight[i])\n",
        "    return weight_final"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KwDnWbA1gnGt"
      },
      "outputs": [],
      "source": [
        "def sum_scaled_weights(scaled_weight_list):\n",
        "    '''Return the sum of the listed scaled weights. The is equivalent to scaled avg of the weights'''\n",
        "    avg_grad = list()\n",
        "    #get the average grad accross all client gradients\n",
        "    for grad_list_tuple in zip(*scaled_weight_list):\n",
        "        layer_mean = tf.math.reduce_sum(grad_list_tuple, axis=0)\n",
        "        avg_grad.append(layer_mean)\n",
        "\n",
        "    return avg_grad"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "63bTkzXzg2m_"
      },
      "outputs": [],
      "source": [
        "def test_model(X_test, Y_test,  model, comm_round):\n",
        "    cce = tf.keras.losses.CategoricalCrossentropy(from_logits=True)\n",
        "    #logits = model.predict(X_test, batch_size=100)\n",
        "    logits = model.predict(X_test)\n",
        "    #print(logits)\n",
        "    loss = cce(Y_test, logits)\n",
        "    acc = accuracy_score( tf.argmax(Y_test, axis=1),tf.argmax(logits, axis=1))\n",
        "    print('comm_round: {} | global_acc: {:.3%} | global_loss: {}'.format(comm_round, acc, loss))\n",
        "    return acc, loss"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XVCtwtcNhvil"
      },
      "source": [
        "# Create Clients"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AxmQLd1WhSe7"
      },
      "outputs": [],
      "source": [
        "#create clients\n",
        "clients = create_clients(maj_3.drop(columns=['attack']).values, color_1hot, num_clients=5, initial='client')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "G6cx_tB-h50L"
      },
      "outputs": [],
      "source": [
        "#process and batch the training data for each client\n",
        "clients_batched = dict()\n",
        "for (client_name, data) in clients.items():\n",
        "    clients_batched[client_name] = batch_data(data)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6C7JqwXhiQtM"
      },
      "outputs": [],
      "source": [
        "#process and batch the test set\n",
        "# test_batched = tf.data.Dataset.from_tensor_slices(testpl.values, encoder.transform(y_test.reshape(-1,1)).all()).batch(len(y_test))\n",
        "test_batched = tf.data.Dataset.from_tensor_slices((testpl.values, encoder.transform(y_test.reshape(-1,1)))).batch(len(y_test))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "eQpUA5wtmDhd"
      },
      "outputs": [],
      "source": [
        "comms_round = 5 #number of global epochs\n",
        "\n",
        "# #create optimizer\n",
        "# lr = 0.01\n",
        "# loss='categorical_crossentropy'\n",
        "# metrics = ['accuracy']\n",
        "# optimizer = SGD(lr=lr,\n",
        "#                 decay=lr / comms_round,\n",
        "#                 momentum=0.9\n",
        "#                )\n",
        "\n",
        "#initialize global model\n",
        "#print(data_list.shape,labels)\n",
        "smlp_global = LocalModel()\n",
        "global_model = smlp_global.build(maj_3.shape[1],5)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0qHiZ9o_06gi",
        "outputId": "8e3c318d-0ac7-48c6-f0d3-368c3a218837"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "<_BatchDataset element_spec=(TensorSpec(shape=(None, 123), dtype=tf.float64, name=None), TensorSpec(shape=(None, 5), dtype=tf.float64, name=None))>\n"
          ]
        }
      ],
      "source": [
        "print(test_batched)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bEuBEWCSpKO9",
        "outputId": "4e3ccbd7-d77f-49fe-d730-b893f5bb99a8"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Progress Bar: 100%|██████████| 5/5 [03:51<00:00, 46.28s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "705/705 [==============================] - 1s 1ms/step\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.87      0.82      0.84      7460\n",
            "           1       0.70      0.91      0.79      9889\n",
            "           2       0.80      0.73      0.76      2421\n",
            "           3       0.81      0.14      0.24      2707\n",
            "           4       0.71      0.07      0.14        67\n",
            "\n",
            "    accuracy                           0.77     22544\n",
            "   macro avg       0.78      0.54      0.55     22544\n",
            "weighted avg       0.78      0.77      0.74     22544\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Progress Bar: 100%|██████████| 5/5 [03:33<00:00, 42.61s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\r  1/705 [..............................] - ETA: 22s"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "705/705 [==============================] - 1s 2ms/step\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.88      0.84      0.86      7460\n",
            "           1       0.75      0.91      0.82      9889\n",
            "           2       0.73      0.72      0.72      2421\n",
            "           3       0.83      0.28      0.42      2707\n",
            "           4       0.20      0.42      0.27        67\n",
            "\n",
            "    accuracy                           0.79     22544\n",
            "   macro avg       0.68      0.63      0.62     22544\n",
            "weighted avg       0.80      0.79      0.77     22544\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Progress Bar: 100%|██████████| 5/5 [03:42<00:00, 44.48s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\r  1/705 [..............................] - ETA: 22s"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "705/705 [==============================] - 1s 2ms/step\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.93      0.84      0.88      7460\n",
            "           1       0.73      0.91      0.81      9889\n",
            "           2       0.65      0.72      0.69      2421\n",
            "           3       0.93      0.22      0.36      2707\n",
            "           4       0.21      0.57      0.30        67\n",
            "\n",
            "    accuracy                           0.78     22544\n",
            "   macro avg       0.69      0.65      0.61     22544\n",
            "weighted avg       0.81      0.78      0.77     22544\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Progress Bar: 100%|██████████| 5/5 [03:52<00:00, 46.53s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\r  1/705 [..............................] - ETA: 22s"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "705/705 [==============================] - 1s 1ms/step\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.92      0.84      0.88      7460\n",
            "           1       0.73      0.91      0.81      9889\n",
            "           2       0.68      0.73      0.70      2421\n",
            "           3       0.88      0.22      0.36      2707\n",
            "           4       0.20      0.55      0.30        67\n",
            "\n",
            "    accuracy                           0.78     22544\n",
            "   macro avg       0.68      0.65      0.61     22544\n",
            "weighted avg       0.80      0.78      0.77     22544\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Progress Bar: 100%|██████████| 5/5 [03:52<00:00, 46.53s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\r  1/705 [..............................] - ETA: 21s"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "705/705 [==============================] - 1s 1ms/step\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.88      0.84      0.86      7460\n",
            "           1       0.73      0.91      0.81      9889\n",
            "           2       0.74      0.73      0.73      2421\n",
            "           3       0.94      0.21      0.34      2707\n",
            "           4       0.23      0.63      0.34        67\n",
            "\n",
            "    accuracy                           0.78     22544\n",
            "   macro avg       0.70      0.66      0.62     22544\n",
            "weighted avg       0.81      0.78      0.76     22544\n",
            "\n"
          ]
        }
      ],
      "source": [
        "#commence global training loop\n",
        "for comm_round in range(comms_round):\n",
        "\n",
        "    # get the global model's weights - will serve as the initial weights for all local models\n",
        "    global_weights = global_model.get_weights()\n",
        "\n",
        "    #initial list to collect local model weights after scalling\n",
        "    scaled_local_weight_list = list()\n",
        "\n",
        "    #randomize client data - using keys\n",
        "    client_names= list(clients_batched.keys())\n",
        "    random.shuffle(client_names)\n",
        "\n",
        "    #loop through each client and create new local model\n",
        "    for client in tqdm(client_names , desc = 'Progress Bar'):\n",
        "        #time.sleep(0.5)\n",
        "        smlp_local = LocalModel()\n",
        "        local_model = smlp_local.build(maj_3.shape[1],5)\n",
        "        # local_model.compile(loss=loss,\n",
        "        #               optimizer=optimizer,\n",
        "        #               metrics=metrics)\n",
        "\n",
        "        #print(local_model.summary())\n",
        "        #print(clients_batched)\n",
        "        #set local model weight to the weight of the global model\n",
        "        local_model.set_weights(global_weights)\n",
        "\n",
        "        #fit local model with client's data\n",
        "        local_model.fit(clients_batched[client], epochs=30, verbose=0)\n",
        "\n",
        "        #scale the model weights and add to list\n",
        "        scaling_factor = weight_scalling_factor(clients_batched, client)\n",
        "        scaled_weights = scale_model_weights(local_model.get_weights(), scaling_factor)\n",
        "        scaled_local_weight_list.append(scaled_weights)\n",
        "\n",
        "        #clear session to free memory after each communication round\n",
        "        K.clear_session()\n",
        "\n",
        "    #to get the average over all the local model, we simply take the sum of the scaled weights\n",
        "    average_weights = sum_scaled_weights(scaled_local_weight_list)\n",
        "\n",
        "    #update global model\n",
        "    global_model.set_weights(average_weights)\n",
        "\n",
        "    #test global model and print out metrics after each communications round\n",
        "    for(X_test, Y_test) in test_batched:\n",
        "       print(classification_report(np.argmax(Y_test,axis=1),np.argmax(global_model.predict(X_test),axis=1)))\n",
        "      # global_acc, global_loss = test_model(X_test, Y_test, global_model, comm_round)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5kiAe8jzgylH"
      },
      "outputs": [],
      "source": [
        "# def installRequirementOnPath(path):\n",
        "#   !pip install -qr $path"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yVIUSxv1imqY"
      },
      "outputs": [],
      "source": [
        "# def create_clients(data_list, num_clients=3, initial='clients'):\n",
        "#     ''' return: a dictionary with keys clients' names and value as\n",
        "#                 data shards - tuple of datas and label lists.\n",
        "#         args:\n",
        "#             data_list: a list of numpy arrays of training data\n",
        "#             label_list:a list of binarized labels for each data\n",
        "#             num_client: number of fedrated members (clients)\n",
        "#             initials: the clients'name prefix, e.g, clients_1\n",
        "\n",
        "#     '''\n",
        "\n",
        "#     #create a list of client names\n",
        "#     client_names = ['{}_{}'.format(initial, i+1) for i in range(num_clients)]\n",
        "\n",
        "#     #shard data and place at each client\n",
        "#     shards = np.array_split(maj_3, num_clients)\n",
        "\n",
        "#     #number of clients must equal number of shards\n",
        "#     assert(len(shards) == len(client_names))\n",
        "\n",
        "#     return {client_names[i] : pd.DataFrame(shards[i]) for i in range(len(client_names))}\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "g60uf-w2K_dJ"
      },
      "source": [
        "# Oversampling"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MaP_UL7tK_M8",
        "outputId": "34dd2ac7-0684-4c8a-df71-d2767105a0b8"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Normal    67343\n",
            "DoS       45927\n",
            "Probe     11656\n",
            "R2L         995\n",
            "U2R          52\n",
            "Name: attack, dtype: int64\n",
            "Probe     67391\n",
            "R2L       67347\n",
            "DoS       67344\n",
            "Normal    67343\n",
            "U2R       67333\n",
            "Name: 0, dtype: int64\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "from imblearn.over_sampling import ADASYN\n",
        "\n",
        "# Load the NSL-KDD dataset into a pandas DataFrame\n",
        "df = maj_3\n",
        "print(df.iloc[:, -1].value_counts())\n",
        "\n",
        "# Separate the features and target variable\n",
        "# X = df.iloc[:, :-1]\n",
        "X = df.drop(columns=['attack'])\n",
        "y = df['attack'].values.reshape(-1,1)\n",
        "\n",
        "# Oversample the minority class using ADASYN\n",
        "ada = ADASYN()\n",
        "X_resampled, y_resampled = ada.fit_resample(X, y)\n",
        "# X_resampled2, y_resampled2 = ada.fit_resample(X_resampled, y_resampled)\n",
        "# Create a new balanced DataFrame\n",
        "df_resampled = pd.concat([pd.DataFrame(X_resampled), pd.DataFrame(y_resampled)], axis=1)\n",
        "\n",
        "# Check the distribution of classes in the new DataFrame\n",
        "print(df_resampled.iloc[:, -1].value_counts())\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BQFIRVsoL0UC",
        "outputId": "bb6fd033-c77c-47c0-d0bd-975dcfcda2f0"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.9/dist-packages/sklearn/preprocessing/_encoders.py:868: FutureWarning: `sparse` was renamed to `sparse_output` in version 1.2 and will be removed in 1.4. `sparse_output` is ignored unless you leave `sparse` to its default value.\n",
            "  warnings.warn(\n"
          ]
        }
      ],
      "source": [
        "from sklearn.preprocessing import OneHotEncoder\n",
        "encoder = OneHotEncoder(sparse=False)\n",
        "# apply on df\n",
        "encoder.fit((df_resampled.iloc[:, -1]).values.reshape(-1,1))\n",
        "color_1hot_resampled = encoder.transform((df_resampled.iloc[:, -1]).values.reshape(-1,1))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qqRRq7I9LWVl"
      },
      "outputs": [],
      "source": [
        "#create clients\n",
        "clients = create_clients((df_resampled.iloc[: , :-1]).values, color_1hot_resampled, num_clients=5, initial='client')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YSkZHtP0m3Uf"
      },
      "outputs": [],
      "source": [
        "#process and batch the training data for each client\n",
        "clients_batched = dict()\n",
        "for (client_name, data) in clients.items():\n",
        "    clients_batched[client_name] = batch_data(data)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "04HiC6Phm8JM"
      },
      "outputs": [],
      "source": [
        "#process and batch the test set\n",
        "# test_batched = tf.data.Dataset.from_tensor_slices(testpl.values, encoder.transform(y_test.reshape(-1,1)).all()).batch(len(y_test))\n",
        "test_batched = tf.data.Dataset.from_tensor_slices((testpl.values, encoder.transform(y_test.reshape(-1,1)))).batch(len(y_test))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cyf81YvonUeh"
      },
      "outputs": [],
      "source": [
        "comms_round = 5 #number of global epochs\n",
        "\n",
        "# #create optimizer\n",
        "# lr = 0.01\n",
        "# loss='categorical_crossentropy'\n",
        "# metrics = ['accuracy']\n",
        "# optimizer = SGD(lr=lr,\n",
        "#                 decay=lr / comms_round,\n",
        "#                 momentum=0.9\n",
        "#                )\n",
        "\n",
        "#initialize global model\n",
        "#print(data_list.shape,labels)\n",
        "smlp_global = LocalModel()\n",
        "global_model = smlp_global.build(df_resampled.shape[1],5)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gmNY6NmHngTn",
        "outputId": "9f9012f6-e0b5-4a4f-d1f0-44fad9a16ed9"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Progress Bar: 100%|██████████| 5/5 [08:35<00:00, 103.11s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "705/705 [==============================] - 1s 1ms/step\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.92      0.86      0.89      7460\n",
            "           1       0.80      0.90      0.85      9889\n",
            "           2       0.77      0.82      0.79      2421\n",
            "           3       0.93      0.41      0.57      2707\n",
            "           4       0.08      0.69      0.15        67\n",
            "\n",
            "    accuracy                           0.82     22544\n",
            "   macro avg       0.70      0.74      0.65     22544\n",
            "weighted avg       0.85      0.82      0.82     22544\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Progress Bar: 100%|██████████| 5/5 [08:39<00:00, 103.82s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " 35/705 [>.............................] - ETA: 1s "
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "705/705 [==============================] - 1s 1ms/step\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.89      0.87      0.88      7460\n",
            "           1       0.80      0.91      0.85      9889\n",
            "           2       0.78      0.80      0.79      2421\n",
            "           3       0.83      0.34      0.48      2707\n",
            "           4       0.11      0.67      0.19        67\n",
            "\n",
            "    accuracy                           0.81     22544\n",
            "   macro avg       0.68      0.72      0.64     22544\n",
            "weighted avg       0.83      0.81      0.81     22544\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Progress Bar: 100%|██████████| 5/5 [08:49<00:00, 105.89s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\r  1/705 [..............................] - ETA: 23s"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "705/705 [==============================] - 1s 2ms/step\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.90      0.86      0.88      7460\n",
            "           1       0.78      0.91      0.84      9889\n",
            "           2       0.73      0.77      0.75      2421\n",
            "           3       0.88      0.33      0.48      2707\n",
            "           4       0.14      0.66      0.24        67\n",
            "\n",
            "    accuracy                           0.81     22544\n",
            "   macro avg       0.69      0.70      0.64     22544\n",
            "weighted avg       0.82      0.81      0.80     22544\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Progress Bar: 100%|██████████| 5/5 [08:48<00:00, 105.72s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\r  1/705 [..............................] - ETA: 21s"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "705/705 [==============================] - 1s 1ms/step\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.90      0.86      0.88      7460\n",
            "           1       0.76      0.91      0.83      9889\n",
            "           2       0.74      0.73      0.73      2421\n",
            "           3       0.78      0.25      0.38      2707\n",
            "           4       0.13      0.61      0.21        67\n",
            "\n",
            "    accuracy                           0.79     22544\n",
            "   macro avg       0.66      0.67      0.61     22544\n",
            "weighted avg       0.81      0.79      0.78     22544\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Progress Bar: 100%|██████████| 5/5 [08:40<00:00, 104.12s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "705/705 [==============================] - 1s 2ms/step\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.90      0.86      0.88      7460\n",
            "           1       0.76      0.91      0.83      9889\n",
            "           2       0.74      0.72      0.73      2421\n",
            "           3       0.76      0.23      0.35      2707\n",
            "           4       0.11      0.63      0.19        67\n",
            "\n",
            "    accuracy                           0.79     22544\n",
            "   macro avg       0.66      0.67      0.60     22544\n",
            "weighted avg       0.80      0.79      0.78     22544\n",
            "\n"
          ]
        }
      ],
      "source": [
        "#commence global training loop\n",
        "for comm_round in range(comms_round):\n",
        "\n",
        "    # get the global model's weights - will serve as the initial weights for all local models\n",
        "    global_weights = global_model.get_weights()\n",
        "\n",
        "    #initial list to collect local model weights after scalling\n",
        "    scaled_local_weight_list = list()\n",
        "\n",
        "    #randomize client data - using keys\n",
        "    client_names= list(clients_batched.keys())\n",
        "    random.shuffle(client_names)\n",
        "\n",
        "    #loop through each client and create new local model\n",
        "    for client in tqdm(client_names , desc = 'Progress Bar'):\n",
        "        #time.sleep(0.5)\n",
        "        smlp_local = LocalModel()\n",
        "        local_model = smlp_local.build(df_resampled.shape[1],5)\n",
        "        # local_model.compile(loss=loss,\n",
        "        #               optimizer=optimizer,\n",
        "        #               metrics=metrics)\n",
        "\n",
        "        #print(local_model.summary())\n",
        "        #print(clients_batched)\n",
        "        #set local model weight to the weight of the global model\n",
        "        local_model.set_weights(global_weights)\n",
        "\n",
        "        #fit local model with client's data\n",
        "        local_model.fit(clients_batched[client], epochs=25, verbose=0)\n",
        "\n",
        "        #scale the model weights and add to list\n",
        "        scaling_factor = weight_scalling_factor(clients_batched, client)\n",
        "        scaled_weights = scale_model_weights(local_model.get_weights(), scaling_factor)\n",
        "        scaled_local_weight_list.append(scaled_weights)\n",
        "\n",
        "        #clear session to free memory after each communication round\n",
        "        K.clear_session()\n",
        "\n",
        "    #to get the average over all the local model, we simply take the sum of the scaled weights\n",
        "    average_weights = sum_scaled_weights(scaled_local_weight_list)\n",
        "\n",
        "    #update global model\n",
        "    global_model.set_weights(average_weights)\n",
        "\n",
        "    #test global model and print out metrics after each communications round\n",
        "    for(X_test, Y_test) in test_batched:\n",
        "       print(classification_report(np.argmax(Y_test,axis=1),np.argmax(global_model.predict(X_test),axis=1)))\n",
        "      # global_acc, global_loss = test_model(X_test, Y_test, global_model, comm_round)"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPq13fm8Tgnz2odnpNxpVdO",
      "include_colab_link": true
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}